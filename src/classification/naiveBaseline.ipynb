{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Have to run the baseline on test set and trained network on test set \n",
    "## What is my test set? Which video kept aside \n",
    "## h5_new_data.py - train_one_aside.h5 and test_one_aside.h5\n",
    "## After merging with old data too - complete_train_one_aside.h5 and complete_test_one_aside.h5\n",
    "## scenes[1] is kept aside \n",
    "\n",
    "## Imports \n",
    "import pdb \n",
    "from path import Path \n",
    "import scipy.io \n",
    "import os \n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import numpy as np \n",
    "import h5py \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "import hdf5storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths to data, collected in november using camera and LiDAR \n",
    "root = Path('/mnt/hdd1/aashi/cmu_data/left_imgs_nov_2')\n",
    "label_dir_left = Path('/mnt/hdd1/aashi/cmu_data/labels_left_2/')\n",
    "det_dir_left = Path('/mnt/hdd1/aashi/cmu_data/det_left_2/')\n",
    "label_dir_right = Path('/mnt/hdd1/aashi/cmu_data/labels_right_2/')\n",
    "det_dir_right = Path('/mnt/hdd1/aashi/cmu_data/det_right_2')\n",
    "scenes = root.dirs()\n",
    "## Detections saved in det_dir_left and det_dir_right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive baseline - no sequence of images\n",
    "## (1) See the current image (2) Read detections \n",
    "## (3) Select the required coordinate (4) Put threshold \n",
    "\n",
    "thresh = 400 \n",
    "\n",
    "for no, scene in enumerate(scenes):\n",
    "    \n",
    "    if no == 1:\n",
    "        name = os.path.split(scene)[-1]\n",
    "        mat = hdf5storage.loadmat('/mnt/hdd1/aashi/cmu_data/mats_nov_2/'\n",
    "                                 + str(name) + '.mat')\n",
    "        left_imgs = mat['left_imgs']\n",
    "#         pdb.set_trace()\n",
    "        arr_left = np.loadtxt(label_dir_left + 'labels_' + name + '.txt')\n",
    "        ## Gaussian smoothing over labels \n",
    "        arr_left = gaussian_filter(arr_left, sigma=0.5)\n",
    "#         arr_left = arr_left > 1e-8\n",
    "        num = arr_left.shape[0]\n",
    "        \n",
    "        ## Record the confusion matrix \n",
    "        confusion_matrix = np.zeros((2,2))\n",
    "        #sequence_len = 10\n",
    "        sequence_len = 20 \n",
    "        for i in range(0, num - sequence_len):\n",
    "            ## leftImg = cv2.imread(scene + '/' + str(i+1) + '.png') \n",
    "            detFile = det_dir_left + 'det_' + str(name) + '/' + str(i+1) + '.txt'\n",
    "            pred_label = 0\n",
    "            if (os.path.getsize(detFile)):\n",
    "                ## Read the bounding box \n",
    "                bboxes = np.loadtxt(detFile)\n",
    "                ## img = left_imgs[0][i]\n",
    "                if (len(bboxes.shape) == 1):\n",
    "                    x1 = int(bboxes[0])\n",
    "                    y1 = int(bboxes[1])\n",
    "                    x2 = int(bboxes[2])\n",
    "                    y2 = int(bboxes[3])\n",
    "                    if (y2 > thresh):\n",
    "                        pred_label = 1\n",
    "                else:\n",
    "                    for k in range(bboxes.shape[0]): \n",
    "                    ## Loop over each pedestrian\n",
    "                        x1 = int(bboxes[k][0])\n",
    "                        y1 = int(bboxes[k][1])\n",
    "                        x2 = int(bboxes[k][2])\n",
    "                        y2 = int(bboxes[k][3])\n",
    "                        ## cv2.rectangle(leftImg, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "                        ## last element is probability - don't care\n",
    "                        if (y2 > thresh):\n",
    "                            pred_label = 1\n",
    "                    ## pdb.set_trace()\n",
    "                \n",
    "            true_label = int(sum(arr_left[i:i+sequence_len]) > 0.1)\n",
    "            confusion_matrix[pred_label][true_label] += 1 \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[272.,  24.],\n",
       "       [375., 465.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = confusion_matrix[1][1]\n",
    "fp = confusion_matrix[1][0]\n",
    "fn = confusion_matrix[0][1]\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1Score = 2*precision*recall/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6997742663656885"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, the naive baseline and OurApproach our comparable \n",
    "## Both predict if 1 second in future on complete video (pedestrian or not)\n",
    "## OurApproach: 0.7233 and naive baseline: 0.58 (at threshold of 500 on 720 image)\n",
    "## OurApproach: 0.7233 and naive baseline: 0.711 (at threshold of 450 on 720 image)\n",
    "\n",
    "## Put the data collected today and see if the performance remains same \n",
    "\n",
    "root = Path('/mnt/hdd1/aashi/cmu_data/left_imgs_dec')\n",
    "label_dir_left = Path('/mnt/hdd1/aashi/cmu_data/labels_left_dec/')\n",
    "det_dir_left = Path('/mnt/hdd1/aashi/cmu_data/det_left_dec/')\n",
    "scenes = root.dirs()\n",
    "\n",
    "for no, scene in enumerate(scenes):\n",
    "    \n",
    "        name = os.path.split(scene)[-1]\n",
    "        mat = scipy.io.loadmat('/mnt/hdd1/aashi/cmu_data/mats_dec/'\n",
    "                                 + str(name) + '.mat')\n",
    "        left_imgs = mat['left_imgs']\n",
    "        arr_left = np.loadtxt(label_dir_left + 'labels_' + name + '.txt')\n",
    "        ## Gaussian smoothing over labels \n",
    "        arr_left = gaussian_filter(arr_left, sigma=0.5)\n",
    "#         arr_left = arr_left > 1e-8\n",
    "        num = arr_left.shape[0]\n",
    "        \n",
    "        ## Record the confusion matrix \n",
    "#         confusion_matrix = np.zeros((2,2))\n",
    "        sequence_len = 10\n",
    "        for i in range(0, num - sequence_len):\n",
    "            ## leftImg = imread(scene + '/' + str(i+1) + '.png') \n",
    "            detFile = det_dir_left + 'det_' + str(name) + '/' + str(i+1) + '.txt'\n",
    "            pred_label = 0\n",
    "            if (os.path.getsize(detFile)):\n",
    "                ## Read the bounding box \n",
    "                bboxes = np.loadtxt(detFile)\n",
    "                ## img = left_imgs[0][i]\n",
    "                if (len(bboxes.shape) == 1):\n",
    "                    x1 = int(bboxes[0])\n",
    "                    y1 = int(bboxes[1])\n",
    "                    x2 = int(bboxes[2])\n",
    "                    y2 = int(bboxes[3])\n",
    "                    if (y2 > thresh):\n",
    "                        pred_label = 1\n",
    "                else:\n",
    "                    for k in range(bboxes.shape[0]): \n",
    "                    ## Loop over each pedestrian\n",
    "                        x1 = int(bboxes[k][0])\n",
    "                        y1 = int(bboxes[k][1])\n",
    "                        x2 = int(bboxes[k][2])\n",
    "                        y2 = int(bboxes[k][3])\n",
    "                        ## cv2.rectangle(leftImg, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "                        ## last element is probability - don't care\n",
    "                        if (y2 > thresh):\n",
    "                            pred_label = 1\n",
    "                    ## pdb.set_trace()\n",
    "                \n",
    "            true_label = int(sum(arr_left[i:i+sequence_len]) > 0.1)\n",
    "            confusion_matrix[pred_label][true_label] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1804.,  159.],\n",
       "       [ 151.,  359.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = confusion_matrix[1][1]\n",
    "fp = confusion_matrix[1][0]\n",
    "fn = confusion_matrix[0][1]\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1Score = 2*precision*recall/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698443579766537\n"
     ]
    }
   ],
   "source": [
    "print(f1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After adding new data: \n",
    "## OurApproach: 0.696, Baseline: 0.69844; "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
